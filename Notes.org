* DONE Local linear things

** Old
One would like to construct a function which allows to locally use
the linear heap. We attempt:

> extract :: Bang A ⊸ A
> extract (Bang x) = x


The above is correct but not too helpful, because when `u` is linear, then
`extract u` will provide a single instance of A.

The GC-oriented reason for this is that the computation of `extract
u` may be suspended, and this would create pointers from the
GC-heap to the linear heap. A value of type `Bang A` is a pointer
to the linear heap, though, so once a whnf is computed it is safe
to extract.

We need a sequentialisation operator. We already have one: Bang
elimination.

> seq_extract :: Bang A ⊸ (A → B) ⊸ B
> seq_extract (Box x) f = f x

Programming with `seq_extract` means sequentialising explicitly
non-linear computations inside of linear computations. It is hard
to introduce intermediate computation which would benefit from the
linear execution model as part of a computation (like a monad,
linearity will leak out of functions and be exposed in its type)


We want to be able to write functions such as the following, in
which putting the result in the GC wouldn't force to do every
intermediate computation in the GC.

> withHeap :: (Heap ⊸ Bang A) ⊸ A

To achieve that we need a primitive with the following type:

   ωΓ ⊢ u ::_1 !A
------------------------------
ωΓ ⊢ strong_extract u ::_ω A

It is important that all variables in the context are unrestricted,
otherwise this could cause pointers from thunks in the GC-heap to
the linear heap. The simplest way to understand the semantics of
`strong_extract` is to translate programs with `strong_extract` to
programs of regular linear logic in CPS, where `strong_extract` is
translated to `seq_extract`. Open: what is the best way to
introduce this primitive in the language?


The CPS translation turns the omega into continuations, but
leaves 1 in direct style. Roughly:

for a term t :_ω A we have ⟦t⟧ :_1 (A → k) ⊸ k


⟦strong_extract u⟧ k = seq_extract u k
⟦t u⟧ k = ⟦u⟧ (⟦t⟧ k)
…


translation of linear things leaves everything untouched except
application:

tω u = ⟦u⟧ t
…


The above suggests the primitive:


kind_of_call/cc :: ((A → ⊥) ⊸ ⊥) → A
** New

We can interpret the expression 

case1 t of Bang x -> u[x]

specially. That is, even in ω contexts, t can be evaluated just
once. (We'll get ω things out of the Bang anyway.)

* DONE Weight Polymorphism 


A ::= ∀ρ. A


t ::= λπ. t | t p

p,q ::= 1 | ω | p+q | p·q


        Γ ⊢ t : A    π fresh for Γ
  ----------------------------------- weight abs
          Γ ⊢ λπ. t : ∀π. A


         Γ ⊢ t : ∀π. A
   ----------------------------------- weight app
         Γ ⊢ t p : A[p/π]



 Γ ⊢ t[π] : A[π]    π fresh for Γ
-----------------------------------
  Γ ⊢ λπ.t : ∀π. A
---------------------------------------
    Γ ⊢ (λπ.t) p : A[p/π]


reduces to


  Γ ⊢ t[p/π] : A[p/π]


Unfortunately we can't really assume that the user will write weight
applications, so we must infer those.
* Subtyping

weights are really intervals. We have thus:
[1..1] ⊆ [0..ω]

but the subtyping relation works the other way, so
ω ⊂ 1

the usual subtyping rule:
B ⊂ B'  A' ⊂ A  π'⊂π
----------------------
A ->π B  ⊂ A' ->π' B'

and so:

  A ⊸ B  ⊂  A -> B

In words: if you expect 1, I can give you ω. So, if you expect an
unrestricted function, I can give you a linear function.

* DONE Copying
for a program to turn a $1$-weight into an $ω$-weight, one may use
the following definition:
\begin{code}
data Bang A = Bang ωA
\end{code}

The expression |case x of { () -> Bang ()}| has type
|Bang A|, but still with weight 1.  The programming pattern described above does not apply
just to the unit type $()$, but to any data type |D|. Indeed, for such
a type we will have a function |D ⊸ Bang D| (this may be even
efficiently implemented by copying a single pointer --- for example if
we have a single array, or a notion of compact region).  Thus at any
point where we have an intermediate result comprised of data only, we
may switch to use the linear heap. In a second phase, this data may
then be moved to the GC heap and used for general consumption.

In that light, the only way to use a linear value from the GC-heap is
to force it first, and then chain computations with |case| --- for
example as follows:
\begin{code}
let x = _1 ()
case ( case x of { () -> Bang () }) of {
  Bang y -> ()
}
\end{code}
This still does not create a pointer from GC-heap to non-GC heap: by the
time |y| is created, the linear value |x| has been freed.

If, on the other hand, |x| had weight $ω$, then we would be in the
usual Haskell case, and the following expression does type:
\begin{code}
let x = _ ω ()
let y = _ ω ( case x of { () -> () } )
in ()
\end{code}

If one wants to use the linear heap 'locally', one must use CPS.

That is:

\begin{code}
doSomethingWithLinearHeap :: (A ⊸ Bang B) ⊸ A ⊸ (B → C) ⊸ C
doSomethingWithLinearHeap f x k = case f x of
  Bang y -> k y

doSomethingWithLinearHeap :: Bang B ⊸ (B → C) ⊸ C
doSomethingWithLinearHeap x k = case x of
  Bang y -> k y
\end{code}

* DONE Safe handles.

There are several options to introduce a Handle safely:

** Linear Monads?
What should monadic bind look like?

-- if the reference is used once, then its action is used once too; probably
(>>=) :: m a ⊸ (a ⊸ m b) → m b

For many monads (IO) actions are never shared. So we probably want just the above type.
Downside: yet result is often to be shared, and this has to be explicit:

(>>=) :: m (Bang a) ⊸ (Bang a ⊸ m b) ⊸ m b

(We have syntactic sugar there anyway... so perhaps we don't care)


In this situation we may write code like

#+BEGIN_SRC haskell
do h <- openFile
   h' <- use h -- kinda ugly
   close h'
#+END_SRC

where

openFile :: String -> IO Handle
hClose :: Handle ⊸ IO ()

** Death to modads. Use contiuations.
Indeed the function returning the bound thing will know more. So we
have:

openFile :: FileHandle ⊸ (Handle ⊸ IO) ⊸ IO
closeFile :: Handle ⊸ IO
hGetLine :: Handle ⊸ (Handle ⊸ String -> IO) IO

** Bang to prevent escape

Can use the same trick as withNewByteArray:

withFile :: FilePath -> (Handle ⊸ IO (Bang a)) ⊸ IO a

However one may miss the advantage compared to

withFile :: FilePath -> (Handle -> IO a) -> IO a

(You have to be trying hard to use withFile incorrectly)

** Linear context

There is a single (context ::1 Context), and we provide

openFile :: FilePath -> Context ⊸ (Context ⊗ Handle)
closeFile :: (Context ⊗ Handle) ⊸ Context

Could even make a dependently-typed version to ensure that the Handle
of the file is not shared behind one's back.

roughly:

openFile :: ∀ paths. (path :: FilePath) -> Context (path:paths) ⊸ (Context paths ⊗ Handle path)
closeFile :: ∀ path paths. (Context paths ⊗ Handle path) ⊸ Context paths

* DONE (Mutable) Array of linear variables

withNewArray :: List a ⊸ (Array a ⊸ Bang k) ⊸ k -- ensuring that arrays are always linear.
updateArray :: Int → a ⊸ Array a ⊸ (Array a ⊗ a)
splitArray :: Int → Array a ⊸ (Array a ⊗ Array a)
foldArray :: b ⊸ (Int → a ⊸ b ⊸ b) → Array a ⊸ b
byteArraySize :: Array a ⊸ (Int ⊗ Array a)

Denotational Semantics:

type Array = List

withNewArray xs k = case k xs of
  Bang r -> r -- note case-bang eval rule.

byteArraySizeThus intermidiate stuff in "k xs" will use the linear heap.

updateArray 0 y (x:xs) = (x, y:xs)
updateArray n y [] = (error "array too small!") y
updateArray n y (x:xs) = case updateArray (n-1) y xs of
  (y',xs') -> (y',x:xs')

splitArray n [] = []
splitArray 0 xs = ([],xs)
splitArray n (x:xs) = case splitArray (n-1) xs of
  (ys,zs) -> (x:ys,zs)

foldArray = foldr

byteArraySize [] = (0,[])
byteArraySize (x:xs) = case byteArraySize xs of
  (n,ys) -> (1+n,y:ys)

* DONE Proof of consistency for dyn. semantics

** Definition: typed reduction rules
We extend the reduction with types, as follows:

   Γ:t  ⇓ρ  Δ:z
becomes:
  Ξ ⊢ (Γ|t ⇓ Δ|z) :ρ A, Σ

where
Ξ : free variables
Γ,Δ: heap states
t,z : term states
Σ : stack (pairs of term and type)


Then we can prove

Ξ ⊢ (Γ|t ⇓ Δ|z) :ρ A, Σ implies  (if Ξ ⊢ (Γ|t :ρ A),Σ ⟶ Ξ ⊢ (Δ|z :ρ A),Σ)

where Ξ ⊢ (Γ|t :ρ A),Σ  ≝   Ξ ⊢ let Γ in (t,terms(Σ)) : (ρA⊗weighted_types(Σ))

Consistency of the heap is implied by well-typedness; so if we start
with a well-typed heap, we will obtain a consistent heap.


The rules are:

  Ξ, x:ωB ⊢ (Γ|e ⇓ Δ|z) :ρ A, Σ
---------------------------------------------------------- shared variable
  Ξ ⊢ (Γ,x :ω B = e | x  ⇓ Δ, x :ω B = z | z) :ρ A, Σ



  Ξ ⊢ (Γ|e ⇓ Δ|z) :1 A, Σ
-------------------------------------------- linear variable
  Ξ ⊢ (Γ,x :1 B = e| x  ⇓  Δ|z) :1 A,  Σ



  Ξ ⊢ (Γ,    x :ρq B = e1 |  t ⇓ Δ|z) :ρ A, Σ
------------------------------------------------- let
  Ξ ⊢ (Γ|let x :q B  = e1 in t ⇓ Δ|z) :ρ A, Σ



    Ξ  ⊢  (Γ|e      ⇓ Δ|λy.u):ρ A →q B, x:qρ A, Σ
    Ξ  ⊢  (Δ|u[x/y] ⇓ Θ|z)   :ρ A →q B,         Σ
----------------------------------------------------- app
    Ξ  ⊢  (Γ|e x ⇓ Θ|z) :ρ B ,Σ


  Ξ,y:pqρ A ⊢ (Γ|e ⇓ Δ|c x) :qρ D, u:ρ C, Σ
  Ξ ⊢ (Δ|u[x/y] ⇓ Θ|z) :ρ C, Σ
---------------------------------------------------- case
  Ξ ⊢ (Γ|case[q] e of {c y ↦ u} ⇓ Θ|z) :ρ C, Σ


  Ξ,y:ω A ⊢ (Γ|e ⇓ Δ|Bang x) :1 D, u:ω C, Σ
  Ξ ⊢ (Δ|u[x/y] ⇓ Θ|z) :ω C, Σ
---------------------------------------------------- case-Bang
  Ξ ⊢ (Γ|case[1] e of {Bang y ↦ u} ⇓ Θ|z) :ω C, Σ




** Small step version


  Γ,z ↦ let x :q B  = e1 in t :ρ A  ⊢ z,Σ   ⟶   Γ,x :qρ B  = e1, z ↦ t ⊢ z:ρ A,Σ
  Γ,z ↦ e x ⊢ z,Σ                           ⟶   Γ,z' ↦ e ⊢ z' ,x :qρ A,Σ
  Γ,z ↦ λy. u ⊢ z,x,Σ                       ⟶  Γ,z' ↦ u[x/y] ⊢ z',Σ

This is ugly and should be polarized.

* Notes on implementation

** Self-deallocating cons cells

Because of the nature of "subtyping" of weights: a location which
expects data of weight $1$ can receive data of weight $ω$; the dynamic
weight of a cons cell is known at creation time but not at the
use-site.

Therefore, the current envisioned implementation path for deallocating
cons cells on use-site (/i.e./ on a ~case~) is to use the thunk
closure: when creating a linear cons cell, the closure, instead of
having code for memoisation would contain the code to deallocate
itself. So forcing a linear thunk would also deallocate it.

This disallows optimisations for linear thunks (but would not affect
shared/gc-d thunks) as linear thunks would need to be actual thunks
(where gc-d thunks can be in a pre-evaluated form).

If such optimisation is useful for linear (self-deallocating) cons
cells, then some dynamic test would have to be performed at the ~case~
site. But it may have an impact on performance of regular Haskell code
(which we would not want: regular Haskell comes first). But the focus
of this proposal is more about minimising gc-pauses (in length and
frequency) than about raw speed.

** Generation of linear-aware code

Ryan Newton:
#+BEGIN_QUOTE
A big selling point of the proposed type system is its backwards
compatibility.  Unannotated programs continue to operate fine in
unrestricted mode.

Maybe the implementation should treat the unrestricted case as default
and the linear one as exceptional. Perhaps generating code for a
function `f :: A -o B` should be seen as a form of SPECIALISE?

Then you can have as many (potentially) linear functions as you like
in the source.  But demand for linear *implementations* would only
kick in at call site in linear context.
#+END_QUOTE

** Toplevel definitions with weight 1

Some application seem to require toplevel definitions with
weight 1. Because these are global, the weight constraint would be
applied at link time.

This has the interesting consequence that such an extension would give
a more first class status to the ~main~ function (for instance there
could be a ~Word#~ of weight 1, and it would be consumed by said
~main~ function to create an executable).
